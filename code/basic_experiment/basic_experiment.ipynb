{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea77fe5",
   "metadata": {},
   "source": [
    "## Код, который не относится к проблеме переведен в `raw`, чтобы не запускаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d034c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.fx\n",
    "from torch.fx.node import Node\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import module2graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a41a2",
   "metadata": {},
   "source": [
    "Тут был код, который замерял время. Сейчас он в файле"
   ]
  },
  {
   "cell_type": "raw",
   "id": "833e58e3",
   "metadata": {},
   "source": [
    "measured_time = dict() # {node_name: [t1,t2,...], ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99157cc4",
   "metadata": {},
   "source": [
    "Научимся семлпировать нужным образом"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76710ce1",
   "metadata": {},
   "source": [
    "class GraphInterperterWithGumbelSoftmaxGamma(GraphInterperterWithGamma):\n",
    "    def __init__(self, mod, gamma_shift=0.0, temperature=1.0):\n",
    "        self.gamma_shift = gamma_shift\n",
    "        self.temperature = temperature\n",
    "        super().__init__(mod)\n",
    "\n",
    "    def init_gammas(self):\n",
    "        i = 0\n",
    "        gammas = []\n",
    "        self.gammas_name = {}\n",
    "        for node in self.graph.nodes:\n",
    "            if node.op == 'call_module':\n",
    "                gammas.append(np.random.randn()+self.gamma_shift)\n",
    "                self.gammas_name[str(node)] = i# перевод в str тут для удобства. в реалньых методах это не нужно\n",
    "                i+=1                        # да и вообще, тут по идее должен быть тензор/параметр\n",
    "        self.gammas =  torch.nn.Parameter(torch.as_tensor(gammas), requires_grad = True)\n",
    "        self.discrete = False \n",
    "\n",
    "    def sample_gammas(self):\n",
    "        if self.discrete:\n",
    "            return self.gammas\n",
    "        else:\n",
    "            d = torch.distributions.RelaxedBernoulli(logits=self.gammas, temperature=self.temperature)\n",
    "            return d.rsample()\n",
    "        \n",
    "    def make_gammas_discrete(self):\n",
    "        self.gammas.data = (self.gammas.data>=0) * 1.0\n",
    "        self.gammas.requires_grad = False \n",
    "        self.discrete = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90ba9f",
   "metadata": {},
   "source": [
    "Получим претрейн на n эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fceacaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/b1/Desktop/m1p/2023-Problem-140/code/basic_experiment/fast_nas_adapt/cv_experiment\n",
      "ExpConfig(img_size=33, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], mse_weight=0.1, strategy='aggressive', batch_size=128, num_epochs=8, log_dir='results/aggressive', device='cpu', lr=0.05, momentum=0.9, weight_decay=0.0005, use_scheduler=False)\n",
      "Using cache found in /Users/b1/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/usr/local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loaded checkpoint 0\n",
      "Loaded checkpoint 1\n",
      "Loaded checkpoint 2\n",
      "Loaded checkpoint 3\n",
      "Loaded checkpoint 4\n",
      "Loaded checkpoint 5\n",
      "Loaded checkpoint 6\n",
      "Loaded checkpoint 7\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS=8\n",
    "\n",
    "%cd fast_nas_adapt/cv_experiment\n",
    "!python3 run.py --strategy=aggressive --log_dir=results/aggressive \\\n",
    "                --num_epochs={NUM_EPOCHS} \\\n",
    "                --device=cpu --lr=5e-2 --weight_decay=5e-4 \\\n",
    "                --classes 0 1 2 3 4 5 6 7 8 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c91b8c9",
   "metadata": {},
   "source": [
    "Замерим время работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02edb62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ResNet18\n",
    "from data import get_dataloaders\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b862d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import ExpConfig\n",
    "config = ExpConfig()\n",
    "config.img_size = 33\n",
    "config.classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "config.model_path = 'results/cifar_8_pretrain/model_last.ckpt'\n",
    "\n",
    "config.mse_weight = 0.1\n",
    "\n",
    "config.strategy = 'aggressive'\n",
    "config.batch_size = 128\n",
    "config.num_epochs = 0\n",
    "config.log_dir = 'results/aggressive'\n",
    "config.device = 'cpu'\n",
    "\n",
    "config.lr = 5e-2\n",
    "config.momentum = 0.9\n",
    "config.weight_decay = 5e-4\n",
    "config.use_scheduler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682c250e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/b1/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/b1/Library/Python/3.8/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/b1/Library/Python/3.8/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18(num_classes=len(config.classes))\n",
    "model_state_dict = torch.load(config.model_path, map_location='cpu')\n",
    "model_state_dict = {key: model_state_dict[key] for key in model_state_dict if 'fc' not in key}\n",
    "model.model.load_state_dict(model_state_dict, strict=False)\n",
    "train_dl, test_dl = get_dataloaders(classes=config.classes, batch_size=config.batch_size,\n",
    "                                    img_size=config.img_size)\n",
    "\n",
    "trainer = Trainer(model, config, train_loader=train_dl, valid_loader=test_dl)\n",
    "trainer._load_checkpoint(config.num_epochs)\n",
    "trainer.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded3ac73",
   "metadata": {},
   "source": [
    "Посмортим предсказания претрейна"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a025de0",
   "metadata": {},
   "source": [
    "accs = []\n",
    "\n",
    "for i, (x, y) in tqdm(enumerate(test_dl), desc='mesuring pretrained accuracy'):\n",
    "    pred = trainer.model.forward(x)[0]\n",
    "    y_pred = pred.argmax(axis=1)\n",
    "    acc = (y.numpy() == y_pred.numpy()).mean()\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(range(len(accs)), accs)\n",
    "plt.gca().set_ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3424a7",
   "metadata": {},
   "source": [
    "Замерим время"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3cc16a46",
   "metadata": {},
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "imodel = GraphInterperterWithGumbelSoftmaxGamma(trainer.model.eval(), 1.0)\n",
    "imodel.eval()\n",
    "\n",
    "for x, y in tqdm(test_dl, desc='measuring time'):\n",
    "    imodel.forward(x)\n",
    "\n",
    "print(x.shape, imodel.forward(x).shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d634e36",
   "metadata": {},
   "source": [
    "Посчитаем статистики"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7e77db2",
   "metadata": {},
   "source": [
    "data = {\n",
    "    'node' : [],\n",
    "    'mean' : [],\n",
    "    'std'  : [],\n",
    "    'len'  : [],\n",
    "    'min'  : [],\n",
    "    'max'  : [],\n",
    "}\n",
    "\n",
    "for k, v in measured_time.items():\n",
    "    data['node'].append(k)\n",
    "    data['mean'].append(np.mean(v))\n",
    "    data['std'].append(np.std(v))\n",
    "    data['len'].append(len(v))\n",
    "    data['min'].append(np.min(v))\n",
    "    data['max'].append(np.max(v))\n",
    "\n",
    "measurments = pd.DataFrame(data)\n",
    "measurments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8f910",
   "metadata": {},
   "source": [
    "Посмотрим на графики врмени (ноды отсортированы по среднему). Время имеет логарифмическую шкалу!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6325910",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "sorted_measurments = measurments.sort_values(by='mean')\n",
    "\n",
    "x = range(len(sorted_measurments))\n",
    "\n",
    "\n",
    "plt.fill_between(x, sorted_measurments['mean']-2*sorted_measurments['std'], \n",
    "                 sorted_measurments['mean']+2*sorted_measurments['std'],\n",
    "                 label='m±2s', alpha=0.5, color='red')\n",
    "\n",
    "plt.fill_between(x, sorted_measurments['min'], sorted_measurments['max'], \n",
    "                 label='min-max', alpha=0.2, color='black')\n",
    "\n",
    "plt.plot(x, sorted_measurments['mean'], label='mean', color='white')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Время, сек.')\n",
    "plt.xlabel('Нода')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0d25d",
   "metadata": {},
   "source": [
    "Гиперпараметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "384b99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imodel = module2graph.GraphInterperterWithGamma(trainer.model.eval())\n",
    "\n",
    "optimizer = torch.optim.Adam(imodel.parameters())\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# lambd = 0\n",
    "# times = torch.tensor(measurments['mean'], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a462e2ad",
   "metadata": {},
   "source": [
    "А вот тут у меня проблемы :с\n",
    "\n",
    "Я думал, что `imodel.forward(x)` просто делает `forwad`, но через граф. Но кажется всё не так просто, потому что вылезает ошибка:\n",
    "\n",
    "> `ValueError: Expected input batch_size (1) to match target batch_size (128).`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78706cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0:\n"
     ]
    }
   ],
   "source": [
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH {epoch_number}:')\n",
    "\n",
    "    imodel.train()\n",
    "\n",
    "    epoch_history = []\n",
    "    for i, (X, y) in tqdm(enumerate(train_dl), 'training'):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = imodel(X)\n",
    "        loss = loss_fn(y_pred, y)# + lambd * imodel.gammas.dot(times)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_history.append(loss.item())\n",
    "    avg_loss = np.mean(epoch_history)\n",
    "\n",
    "    imodel.eval()\n",
    "    \n",
    "    print('epoch trained')\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, (X, y) in tqdm(enumerate(test_dl), 'validating'):\n",
    "        running_vloss += loss_fn(imodel(X), y)\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72d493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
