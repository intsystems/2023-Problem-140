{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d034c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.fx\n",
    "from torch.fx.node import Node\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fast_nas_adapt.src.module2graph\n",
    "from fast_nas_adapt.src.module2graph import GraphInterperterWithGamma, GraphInterperterWithBernGamma\n",
    "from fast_nas_adapt.src.resnet18 import ResNet18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a41a2",
   "metadata": {},
   "source": [
    "Тут был код, который замерял время. Сейчас он в файле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86333e9a-0ec1-4323-9de3-bb15c6efedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphInterperterWithGumbelSoftmaxGamma(GraphInterperterWithGamma):\n",
    "    def __init__(self, mod, gamma_shift=0.0, temperature=1.0):\n",
    "        self.gamma_shift = gamma_shift\n",
    "        self.temperature = temperature\n",
    "        super().__init__(mod)\n",
    "\n",
    "    def init_gammas(self):\n",
    "        i = 0\n",
    "        gammas = []\n",
    "        self.gammas_name = {}\n",
    "        for node in self.graph.nodes:\n",
    "            if node.op == 'call_module':\n",
    "                gammas.append(np.random.randn()+self.gamma_shift)\n",
    "                self.gammas_name[str(node)] = i# перевод в str тут для удобства. в реалньых методах это не нужно\n",
    "                i+=1                        # да и вообще, тут по идее должен быть тензор/параметр\n",
    "        self.gammas =  torch.nn.Parameter(torch.as_tensor(gammas), requires_grad = True)\n",
    "        self.discrete = False \n",
    "\n",
    "    def sample_gammas(self):\n",
    "        if self.discrete:\n",
    "            return self.gammas\n",
    "        else:\n",
    "            d = torch.distributions.RelaxedBernoulli(logits=self.gammas, temperature=self.temperature)\n",
    "            return d.rsample()\n",
    "        \n",
    "    def make_gammas_discrete(self):\n",
    "        self.gammas.data = (self.gammas.data>=0) * 1.0\n",
    "        self.gammas.requires_grad = False \n",
    "        self.discrete = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90ba9f",
   "metadata": {},
   "source": [
    "Получим претрейн на n эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02edb62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_nas_adapt.src.cifar_data import get_dataloaders\n",
    "from fast_nas_adapt.src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682c250e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/b1/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/b1/Library/Python/3.8/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/b1/Library/Python/3.8/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(num_classes=10)\n",
    "\n",
    "\n",
    "train_dl, test_dl = get_dataloaders(classes=range(10), batch_size=64,\n",
    "                                    img_size=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abad33b6-838a-4f2f-a660-90a6c856eb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('fast_nas_adapt/data/model_23.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f4cc70-5acb-495b-868e-e00d2b93d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(model, dataloader, device):\n",
    "    model = model.to(device)\n",
    "    n_true = 0\n",
    "    n_tot = 0\n",
    "    for i, (X, y) in tqdm(enumerate(dataloader), 'validating'):\n",
    "        if X.shape[0] != 64:\n",
    "            continue\n",
    "        n_true += (model(X.to(device)).argmax(-1) == y.to(device)).sum().item()\n",
    "        n_tot += 64\n",
    "    return n_true / n_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb75b59a-e807-4ac7-b452-09344836505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validating: 157it [00:32,  4.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6464342948717948"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, test_dl, 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0d25d",
   "metadata": {},
   "source": [
    "Гиперпараметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384b99a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9854, 0.9622, 0.9940, 0.9864, 0.9501, 0.9873, 0.9878, 0.9672, 0.9231,\n",
      "        0.9770, 0.9550, 0.9899, 0.9966, 0.9054, 0.9719, 0.9955, 0.9875, 0.9847,\n",
      "        0.9914, 0.9788, 0.9910, 0.9117, 0.9902, 0.9712, 0.9939, 0.9483, 0.9647,\n",
      "        0.9793, 0.9759, 0.9857, 0.9708, 0.9937, 0.9636, 0.9611, 0.8591, 0.9919,\n",
      "        0.9822, 0.9795, 0.9729, 0.9790, 0.9432, 0.9704, 0.9777, 0.9937, 0.9905,\n",
      "        0.9808, 0.9781, 0.9789, 0.9969, 0.9987, 0.9185, 0.9567, 0.9519, 0.9754,\n",
      "        0.9745, 0.9747, 0.9908, 0.9596, 0.9951, 0.9472],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validating: 157it [00:34,  4.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.390224358974359,\n",
       " tensor([1.0000, 0.9998, 0.9995, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         0.9990, 1.0000, 1.0000, 1.0000, 0.9994, 0.7397, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9996, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.9938, 1.0000, 0.6093, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9856, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000],\n",
       "        grad_fn=<ClampBackward1>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "imodel = GraphInterperterWithGumbelSoftmaxGamma(model.eval(), 4, temperature=0.2).to(device)\n",
    "optimizer = torch.optim.Adam([imodel.gammas], lr=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "times = torch.ones_like(imodel.gammas).detach().div(imodel.gammas.numel())  # uniform\n",
    "lambd = 2.0\n",
    "print(imodel.gammas.sigmoid())\n",
    "\n",
    "validate(imodel, test_dl, device), imodel.sample_gammas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d93e6bd6-91fa-4179-ba05-902d299d40ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "with torch.no_grad():\n",
    "    x = torch.randn(64, 3, 32, 32).to(device)\n",
    "    print(model(x).shape, imodel(x).shape)\n",
    "    # assert (model(x) - imodel(x)).abs().mean().item() < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f78706cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  16%|█████                          | 128/782 [03:34<18:18,  1.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mimodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y\u001b[38;5;241m.\u001b[39mto(device)) \u001b[38;5;241m+\u001b[39m lambd \u001b[38;5;241m*\u001b[39m imodel\u001b[38;5;241m.\u001b[39msample_gammas()\u001b[38;5;241m.\u001b[39mdot(times)\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/m1p/2023-Problem-140/code/Archive (2)/fast_nas_adapt/src/module2graph.py:121\u001b[0m, in \u001b[0;36mGraphInterperterWithGamma.forward\u001b[0;34m(self, intermediate, *args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(self_obj, node\u001b[38;5;241m.\u001b[39mtarget)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_module\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mload_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mload_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msampled_gammas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgammas_name\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m intermediate:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "best_acc = 0.0\n",
    "epoch_history = []\n",
    "val_accs = []\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH {epoch_number}:')\n",
    "\n",
    "    imodel.train()\n",
    "\n",
    "    for i, (X, y) in tqdm(enumerate(train_dl), 'training', total=len(train_dl)):\n",
    "        if X.shape[0] != 64:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = imodel(X.to(device))\n",
    "        loss = loss_fn(y_pred, y.to(device)) + lambd * imodel.sample_gammas().dot(times)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_history.append((y_pred.argmax(-1) == y.to(device)).float().mean().item())\n",
    "        \n",
    "        if i == 300:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    avg_loss = np.mean(epoch_history)\n",
    "\n",
    "    imodel.eval()\n",
    "    \n",
    "\n",
    "    val_acc = validate(imodel, test_dl, device)\n",
    "    val_accs.append(val_acc)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, val_acc))\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        # model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        # torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bacaef-33f8-4dd5-ad6e-b49108632d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_accs)\n",
    "max(val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0379d1a-54a9-4dcc-9648-afb5bcc5620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(imodel.gammas.detach().cpu().sigmoid() >= 0.5).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682783b-e4e6-4bc9-9c02-60c75467aafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
